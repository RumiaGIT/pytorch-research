{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNqPNlYylluR"
   },
   "source": [
    "# 05. PyTorch Going Modular Exercises\n",
    "\n",
    "> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can.\n",
    "\n",
    "## Resources and solutions\n",
    "\n",
    "* These exercises/solutions are based on [section 05. PyTorch Going Modular](https://www.learnpytorch.io/05_pytorch_going_modular/) of the Learn PyTorch for Deep Learning course by Zero to Mastery.\n",
    "\n",
    "**Solutions:** \n",
    "\n",
    "Try to complete the code below *before* looking at these.\n",
    "\n",
    "* See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/ijgFhMK3pp4).\n",
    "* See an example [solutions notebook for these exercises on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/05_pytorch_going_modular_exercise_solutions.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bicbWSrPmfTU"
   },
   "source": [
    "## 1. Turn the code to get the data (from section 1. Get Data) into a Python script, such as `get_data.py`.\n",
    "\n",
    "* When you run the script using `python get_data.py` it should check if the data already exists and skip downloading if it does.\n",
    "* If the data download is successful, you should be able to access the `pizza_steak_sushi` images from the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T14:00:36.541396Z",
     "start_time": "2023-03-25T14:00:33.735737Z"
    },
    "id": "r0BCn1XIYZ8c"
   },
   "outputs": [],
   "source": [
    "#%%writefile modular_scripts/get_data.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for custom image classification data.\n",
    "\"\"\"\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates training and testing DataLoaders \n",
    "    Takes in training and testing directory paths and turns their contents into PyTorch datasets, and then into PyTorch DataLoaders\n",
    "    \n",
    "    Parameters:\n",
    "        train_dir: Path to the training directory\n",
    "        test_dir: Path to the testing directory\n",
    "        transform: A Torchvision transform to perform on the training and testing data\n",
    "        batch_size: Sample size for the batches in the DataLoaders\n",
    "        num_workers: Number of workers (CPU/GPU cores) per DataLoader\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "        Where class_names is a list of the target classes.\n",
    "    \"\"\"\n",
    "    train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "    \n",
    "    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, num_workers=NUM_WORKERS, shuffle=True)\n",
    "    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=NUM_WORKERS, shuffle=False)\n",
    "    \n",
    "    class_names = train_data.classes\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T14:00:36.557388Z",
     "start_time": "2023-03-25T14:00:36.549391Z"
    },
    "id": "_LrUOIC-YOP9"
   },
   "outputs": [],
   "source": [
    "# Example running of get_data.py\n",
    "#!python get_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjyn7LU3mvkR"
   },
   "source": [
    "## 2. Use [Python's `argparse` module](https://docs.python.org/3/library/argparse.html) to be able to send the `train.py` custom hyperparameter values for training procedures.\n",
    "* Add an argument flag for using a different:\n",
    "  * Training/testing directory\n",
    "  * Learning rate\n",
    "  * Batch size\n",
    "  * Number of epochs to train for\n",
    "  * Number of hidden units in the TinyVGG model\n",
    "    * Keep the default values for each of the above arguments as what they already are (as in notebook 05).\n",
    "* For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs: `python train.py --learning_rate 0.003 batch_size 64 num_epochs 20`.\n",
    "* **Note:** Since `train.py` leverages the other scripts we created in section 05, such as, `model_builder.py`, `utils.py` and `engine.py`, you'll have to make sure they're available to use too. You can find these in the [`going_modular` folder on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular/going_modular). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T14:00:36.587369Z",
     "start_time": "2023-03-25T14:00:36.564385Z"
    },
    "id": "MKNDUp45YaW-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/train_args.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/train_args.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model.\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy\n",
    "import data_setup, engine, model_builder, utils\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Training a model with modular scripts with hyperparameters\")\n",
    "    parser.add_argument(\"--train_dir\", default=\"data/PizzaSteakSushi/train\", type=str, help=\"The directory of the training data\")\n",
    "    parser.add_argument(\"--test_dir\", default=\"data/PizzaSteakSushi/test\", type=str, help=\"The directory of the testing data\")\n",
    "    parser.add_argument(\"--num_epochs\", default=10, type=int, help=\"The number of epochs to train for\")\n",
    "    parser.add_argument(\"--batch_size\", default=32, type=int, help=\"The number of samples per batch\")\n",
    "    parser.add_argument(\"--hidden_units\", default=10, type=int, help=\"The number of hidden units in the model\")\n",
    "    parser.add_argument(\"--learning_rate\", default=0.001, type=float, help=\"The learning rate of the model\")\n",
    "\n",
    "    args=parser.parse_args()\n",
    "\n",
    "    NUM_EPOCHS = args.num_epochs\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    HIDDEN_UNITS = args.hidden_units\n",
    "    LEARNING_RATE = args.learning_rate\n",
    "    print(f\"[INFO] Training for {NUM_EPOCHS} epochs, batch size: {BATCH_SIZE}, hidden units: {HIDDEN_UNITS}, learning rate: {LEARNING_RATE}\")\n",
    "\n",
    "    TRAIN_DIR = args.train_dir\n",
    "    TEST_DIR = args.test_dir\n",
    "\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "        train_dir=TRAIN_DIR,\n",
    "        test_dir=TEST_DIR,\n",
    "        transform=data_transform,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    model = model_builder.TinyVGG(\n",
    "        in_shape=3,\n",
    "        hidden=HIDDEN_UNITS,\n",
    "        out_shape=len(class_names)\n",
    "    )\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "    metric_fn = Accuracy(task=\"multiclass\", num_classes=len(class_names))\n",
    "\n",
    "    engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        metric_fn=metric_fn,\n",
    "        epochs=NUM_EPOCHS\n",
    "    )\n",
    "    \n",
    "    utils.save_model(\n",
    "        model=model,\n",
    "        target_dir=\"models\",\n",
    "        model_name=\"05_pytorch_going_modular_tinyvgg_args.pth\"\n",
    "    )\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T14:03:30.981490Z",
     "start_time": "2023-03-25T14:00:36.595366Z"
    },
    "id": "LzaJl39lC40N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training for 5 epochs, batch size: 32, hidden units: 10, learning rate: 0.001\n",
      "Epoch: 0\n",
      "--------\n",
      "Train Loss: 1.1062828302383423, Train Acc: 0.30859375 | Test Loss: 1.0988644361495972, Test Acc: 0.3020833432674408\n",
      "Epoch: 1\n",
      "--------\n",
      "Train Loss: 1.0993874073028564, Train Acc: 0.33203125 | Test Loss: 1.0694524049758911, Test Acc: 0.5416666865348816\n",
      "Epoch: 2\n",
      "--------\n",
      "Train Loss: 1.0866265296936035, Train Acc: 0.36328125 | Test Loss: 1.0801142454147339, Test Acc: 0.4517045319080353\n",
      "Epoch: 3\n",
      "--------\n",
      "Train Loss: 1.085021734237671, Train Acc: 0.37890625 | Test Loss: 1.0572490692138672, Test Acc: 0.59375\n",
      "Epoch: 4\n",
      "--------\n",
      "Train Loss: 1.0626752376556396, Train Acc: 0.3984375 | Test Loss: 1.0673949718475342, Test Acc: 0.4630681574344635\n",
      "Saving model to: models\\05_pytorch_going_modular_tinyvgg_args.pth\n"
     ]
    }
   ],
   "source": [
    "# Example running of train.py\n",
    "# Instead of importing the files into this Jupyter Notebook, it's ran as a Python command line command\n",
    "# This simulates running the command in the terminal\n",
    "# It also circumvents issues with directory paths that would occur when importing the file\n",
    "!python modular_scripts/train_args.py --num_epochs 5 --batch_size 32 --hidden_units 10 --learning_rate 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2g6EEYvm-46"
   },
   "source": [
    "## 3. Create a Python script to predict (such as `predict.py`) on a target image given a file path with a saved model.\n",
    "\n",
    "* For example, you should be able to run the command `python predict.py some_image.jpeg` and have a trained PyTorch model predict on the image and return its prediction.\n",
    "* To see example prediction code, check out the [predicting on a custom image section in notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function). \n",
    "* You may also have to write code to load in a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T14:03:31.012474Z",
     "start_time": "2023-03-25T14:03:30.986492Z"
    },
    "id": "HU7W6VZfYawP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/predict.py\n",
    "\"\"\"\n",
    "Predicts the class of a given image using a TinyVGG model\n",
    "\"\"\"\n",
    "import torch\n",
    "import torchvision\n",
    "import argparse\n",
    "import model_builder\n",
    " \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--image\", help=\"Target image to predict the class of\")\n",
    "parser.add_argument(\"--model_path\", default=\"models/05_pytorch_going_modular_tinyvgg_args.pth\", \n",
    "                        type=str, help=\"Target model to use for the class prediction\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "IMG_PATH = args.image\n",
    "MODEL_PATH = args.model_path\n",
    "class_names = [\"pizza\", \"steak\", \"sushi\"]\n",
    "\n",
    "def load_model(path=MODEL_PATH):\n",
    "    model = model_builder.TinyVGG(\n",
    "        in_shape=3,\n",
    "        hidden=10,\n",
    "        out_shape=3\n",
    "    )\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model\n",
    "\n",
    "def predict_on_image(image_path=IMG_PATH, model_path=MODEL_PATH):\n",
    "    model = load_model(MODEL_PATH)\n",
    "    image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
    "    image = image / 255.\n",
    "    transform = torchvision.transforms.Resize(size=(64, 64))\n",
    "    image = transform(image)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred_logits = model(image.unsqueeze(dim=0))\n",
    "        pred_probs = torch.softmax(pred_logits, dim=1)\n",
    "        pred_label = torch.argmax(pred_probs, dim=1)\n",
    "        pred_label_class = class_names[pred_label]\n",
    "        \n",
    "    print(f\"[INFO] Pred class: {pred_label_class}, Pred prob: {pred_probs.max():.3f}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    predict_on_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-25T14:03:33.786965Z",
     "start_time": "2023-03-25T14:03:31.016471Z"
    },
    "id": "Zcvw9sitIn6r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Pred class: steak, Pred prob: 0.505\n"
     ]
    }
   ],
   "source": [
    "# Example running of predict.py \n",
    "!python modular_scripts/predict.py --image \"data/PizzaSteakSushi/test/steak/502076.jpg\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNcX0JATB1YsaAFGNe0TGWq",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "05_pytorch_going_modular_exercise_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
