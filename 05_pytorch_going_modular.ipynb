{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9329633c",
   "metadata": {},
   "source": [
    "# 05. Going Modular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf132dca",
   "metadata": {},
   "source": [
    "https://www.learnpytorch.io/05_pytorch_going_modular/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42119266",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0668168",
   "metadata": {},
   "source": [
    "- [All Links in Document](#links)\n",
    "- [PyTorch Going Modular](#modular)\n",
    "- [Data Setup](#setup)\n",
    "- [Building a Model](#buildmodel)\n",
    "- [Saving a Model](#savemodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdaba57",
   "metadata": {},
   "source": [
    "## All Links in Document <a name=\"links\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbee4a",
   "metadata": {},
   "source": [
    "- https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c64421",
   "metadata": {},
   "source": [
    "## PyTorch Going Modular <a name=\"modular\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c204e3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.546681Z",
     "start_time": "2023-03-19T17:47:43.484479Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c3d5cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.562748Z",
     "start_time": "2023-03-19T17:47:46.549664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e123d0",
   "metadata": {},
   "source": [
    "What exactly does it mean to go modular? Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality. For example, a series of cells in a Jupyter Notebook file could be transformed into the following files:\n",
    "\n",
    "- data_setup.py: A file to prepare and download data if needed\n",
    "- engine.py: A file containing various training functions\n",
    "- model.py: A file to create a PyTorch model\n",
    "- train.py: A file to leverage all the other files and train a large PyTorch model\n",
    "- utils.py: A file to store helpful utility functions in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c65d27",
   "metadata": {},
   "source": [
    "The naming convention and distribution of code among files is obviously customizable and depends on context. Notebooks are fantastic for iteratively exploring and running experiments quickly. However, for larger scale projects you may find Python scripts more reproducible and easier to run. There's arguments to be had for both sides of the coin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5cb1b",
   "metadata": {},
   "source": [
    "Jupyter Notebook files are easy to start with, they're easy to share, and they're very visual-oriented. However, versioning can be difficult, it's harder to use only specific parts, and text and graphics can get in the way of the code. Python scripts can package code together, can easily use git for versioning, many open source projects use Python scripts, and larger projects can be run on cloud vendors (so can Notebook files but there's not as much support). However, experimenting with code isn't as visual and you usually have to run the whole script instead of a single code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd857e61",
   "metadata": {},
   "source": [
    "<img src=\"images/05_pytorch_script_example.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c890e",
   "metadata": {},
   "source": [
    "Many code repositories for PyTorch-based ML projects have instructions on how to run the PyTorch code in the form of Python scripts. The above is such an example, tailored after usage of the TinyVGG model that has been recreated in previous Notebooks. Here, `train.py` is the target Python script and the other sections are argument flags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84305e",
   "metadata": {},
   "source": [
    "Note: it's not necessary to create Python scripts via a notebook. It's possible to create them directly through an IDE such as Visual Studio Code. Creating the scripts through code cells in this Notebook is just to show off one way of creating Python script files and to keep the lesson in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f82a75",
   "metadata": {},
   "source": [
    "## Data Setup <a name=\"setup\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9cd113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.578749Z",
     "start_time": "2023-03-19T17:47:46.566747Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = Path(\"data/PizzaSteakSushi\")\n",
    "TRAIN_DIR = Path(f\"{IMAGE_PATH}/train\")\n",
    "TEST_DIR = Path(f\"{IMAGE_PATH}/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f4e76f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.594732Z",
     "start_time": "2023-03-19T17:47:46.583736Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5cc0e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.642704Z",
     "start_time": "2023-03-19T17:47:46.598729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for custom image classification data.\n",
    "\"\"\"\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates training and testing DataLoaders\n",
    "    \n",
    "    Takes in training and testing directory paths and turns their contents into PyTorch datasets, and then into PyTorch DataLoaders\n",
    "    \n",
    "    Parameters:\n",
    "        train_dir: Path to the training directory\n",
    "        test_dir: Path to the testing directory\n",
    "        transform: A Torchvision transform to perform on the training and testing data\n",
    "        batch_size: Sample size for the batches in the DataLoaders\n",
    "        num_workers: Number of workers (CPU/GPU cores) per DataLoader\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "        Where class_names is a list of the target classes.\n",
    "    \"\"\"\n",
    "    # Create datasets with datasets.ImageFolder()\n",
    "    train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = train_data.classes\n",
    "    \n",
    "    # Transform datasets into DataLoaders\n",
    "    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, num_workers=NUM_WORKERS, shuffle=True)\n",
    "    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=NUM_WORKERS, shuffle=False)\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23431d",
   "metadata": {},
   "source": [
    "The creation of DataLoaders can now be achieved by importing the created file and its functions into this Jupyter Notebook file and then calling the function and supplying the necessary arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30defdd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.673544Z",
     "start_time": "2023-03-19T17:47:46.647714Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing data_setup.py\n",
    "from modular_scripts import data_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b81b57a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.689546Z",
     "start_time": "2023-03-19T17:47:46.677543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating DataLoaders and class names\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(TRAIN_DIR, \n",
    "                                                                               TEST_DIR, \n",
    "                                                                               simple_transform, \n",
    "                                                                               32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e2e6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.704543Z",
     "start_time": "2023-03-19T17:47:46.693533Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many batches each DataLoader has\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180341f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.720528Z",
     "start_time": "2023-03-19T17:47:46.708524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12104d72",
   "metadata": {},
   "source": [
    "## Building a Model <a name=\"buildmodel\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d477051",
   "metadata": {},
   "source": [
    "In the previous chapters, image classification models mimicking a TinyVGG architecture were created at multiple points. While recreating the code multiple times is good for practice, saving the code in an external Python file will prove to be useful for reusability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c55eef35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.736508Z",
     "start_time": "2023-03-19T17:47:46.727525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/model_builder.py\n",
    "\"\"\"\n",
    "Contains PyTorch model code to instantiate a TinyVGG model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates the TinyVGG architecture.\n",
    "    \n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "    \n",
    "    Parameters:\n",
    "        in_shape: An integer indicating the number of input layer neurons.\n",
    "        hidden: An integer indicating the number of hidden layer neurons.\n",
    "        out_shape: An integer indicating the number of output layer neurons.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_shape: int, hidden: int, out_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_shape, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden*13*13, out_features=out_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c8482",
   "metadata": {},
   "source": [
    "Instead of coding the TinyVGG model from scratch every time, it's now possible to create it by importing the relevant file, function, and calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba49b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.768507Z",
     "start_time": "2023-03-19T17:47:46.740508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing model_builder.py\n",
    "from modular_scripts import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc41fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.800489Z",
     "start_time": "2023-03-19T17:47:46.773490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating an instance of the TinyVGG model class\n",
    "torch.manual_seed(42)\n",
    "model_0 = model_builder.TinyVGG(3, 10, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9725195a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.832455Z",
     "start_time": "2023-03-19T17:47:46.804471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [1, 3]                    --\n",
       "├─Sequential: 1-1                        [1, 10, 30, 30]           --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 62, 62]           280\n",
       "│    └─ReLU: 2-2                         [1, 10, 62, 62]           --\n",
       "│    └─Conv2d: 2-3                       [1, 10, 60, 60]           910\n",
       "│    └─ReLU: 2-4                         [1, 10, 60, 60]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 10, 30, 30]           --\n",
       "├─Sequential: 1-2                        [1, 10, 13, 13]           --\n",
       "│    └─Conv2d: 2-6                       [1, 10, 28, 28]           910\n",
       "│    └─ReLU: 2-7                         [1, 10, 28, 28]           --\n",
       "│    └─Conv2d: 2-8                       [1, 10, 26, 26]           910\n",
       "│    └─ReLU: 2-9                         [1, 10, 26, 26]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 10, 13, 13]           --\n",
       "├─Sequential: 1-3                        [1, 3]                    --\n",
       "│    └─Flatten: 2-11                     [1, 1690]                 --\n",
       "│    └─Linear: 2-12                      [1, 3]                    5,073\n",
       "==========================================================================================\n",
       "Total params: 8,083\n",
       "Trainable params: 8,083\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 5.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.71\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.79\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviewing the model summary\n",
    "summary(model_0, input_size=[1, 3, 64, 64], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce1bfb",
   "metadata": {},
   "source": [
    "It's also possible to save the training and testing loops in external files as well. This essentially has been done multiple times already as the training and testing loops were turned into functions at several points. The same will be done here, but the code is saved in an external file to increase reusability even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cba782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.863437Z",
     "start_time": "2023-03-19T17:47:46.836450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/engine.py\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "import torchmetrics\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               metric_fn: torchmetrics.classification) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for a single epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        metric_fn: A PyTorch metric to track how well the model performs.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of training loss and training accuracy metrics.\n",
    "        In the form (train_loss, train_accuracy).\n",
    "    \"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_logits = model(X)\n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "        loss = loss_fn(y_logits, y)\n",
    "        train_loss += loss\n",
    "        train_acc += metric_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              metric_fn: torchmetrics.classification) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Tests a PyTorch model for a single epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        metric_fn: A PyTorch metric to track how well the model performs.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of testing loss and testing accuracy metrics.\n",
    "        In the form (test_loss, test_accuracy).\n",
    "    \"\"\"\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            test_logits = model(X)\n",
    "            test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "            test_loss += loss_fn(test_logits, y)\n",
    "            test_acc += metric_fn(test_pred, y)\n",
    "            \n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          metric_fn: torchmetrics.classification,\n",
    "          epochs: int) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Trains and tests a PyTorch model.\n",
    "    \n",
    "    Passes a target PyTorch models through train_step() and test_step() functions.\n",
    "    For a number of epochs, training and testing steps for model the model are performed.\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "    \n",
    "    Parameters:\n",
    "        model: A PyTorch model to be trained.\n",
    "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        metric_fn: A PyTorch metric to track how well the model performs.\n",
    "        epochs: An integer indicating how many epochs to train for.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and testing accuracy metrics. \n",
    "        Each metric has a value in a list for each epoch.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, metric_fn)\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn, metric_fn)\n",
    "        \n",
    "        print(f\"Epoch: {epoch}\\n--------\")\n",
    "        print(f\"Train Loss: {train_loss}, Train Acc: {train_acc} | Test Loss: {test_loss}, Test Acc: {test_acc}\")\n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bf138d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.879427Z",
     "start_time": "2023-03-19T17:47:46.867435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing engine.py\n",
    "from modular_scripts import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e28c850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:47:46.909408Z",
     "start_time": "2023-03-19T17:47:46.885424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the loss function, optimizer, and metric function to pass to the model\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "212a55d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-19T17:48:40.060014Z",
     "start_time": "2023-03-19T17:47:46.914405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "--------\n",
      "Train Loss: 1.1045265197753906, Train Acc: 0.265625 | Test Loss: 1.0925774574279785, Test Acc: 0.2604166567325592\n",
      "Epoch: 1\n",
      "--------\n",
      "Train Loss: 1.083570957183838, Train Acc: 0.38671875 | Test Loss: 1.0558981895446777, Test Acc: 0.5416666865348816\n",
      "Epoch: 2\n",
      "--------\n",
      "Train Loss: 1.0705418586730957, Train Acc: 0.40234375 | Test Loss: 1.0242347717285156, Test Acc: 0.5416666865348816\n",
      "Epoch: 3\n",
      "--------\n",
      "Train Loss: 1.0964175462722778, Train Acc: 0.28515625 | Test Loss: 1.000772476196289, Test Acc: 0.5625\n",
      "Epoch: 4\n",
      "--------\n",
      "Train Loss: 1.0600786209106445, Train Acc: 0.359375 | Test Loss: 1.0676933526992798, Test Acc: 0.374053031206131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(1.1045, grad_fn=<DivBackward0>),\n",
       "  tensor(1.0836, grad_fn=<DivBackward0>),\n",
       "  tensor(1.0705, grad_fn=<DivBackward0>),\n",
       "  tensor(1.0964, grad_fn=<DivBackward0>),\n",
       "  tensor(1.0601, grad_fn=<DivBackward0>)],\n",
       " 'train_acc': [tensor(0.2656),\n",
       "  tensor(0.3867),\n",
       "  tensor(0.4023),\n",
       "  tensor(0.2852),\n",
       "  tensor(0.3594)],\n",
       " 'test_loss': [tensor(1.0926),\n",
       "  tensor(1.0559),\n",
       "  tensor(1.0242),\n",
       "  tensor(1.0008),\n",
       "  tensor(1.0677)],\n",
       " 'test_acc': [tensor(0.2604),\n",
       "  tensor(0.5417),\n",
       "  tensor(0.5417),\n",
       "  tensor(0.5625),\n",
       "  tensor(0.3741)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.train(model_0, train_dataloader, test_dataloader, loss_fn, optimizer, metric_fn, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb4c5b",
   "metadata": {},
   "source": [
    "## Saving a Model <a name=\"savemodel\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aadc234",
   "metadata": {},
   "source": [
    "Next up, saving a model the modular way!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
