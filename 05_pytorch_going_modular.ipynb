{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9329633c",
   "metadata": {},
   "source": [
    "# 05. Going Modular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf132dca",
   "metadata": {},
   "source": [
    "https://www.learnpytorch.io/05_pytorch_going_modular/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42119266",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0668168",
   "metadata": {},
   "source": [
    "- [All Links in Document](#links)\n",
    "- [PyTorch Going Modular](#modular)\n",
    "- [Data Setup](#setup)\n",
    "- [Building a Model](#buildmodel)\n",
    "- [Saving a Model](#savemodel)\n",
    "- [Everything Combined](#combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdaba57",
   "metadata": {},
   "source": [
    "## All Links in Document <a name=\"links\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbee4a",
   "metadata": {},
   "source": [
    "- https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c64421",
   "metadata": {},
   "source": [
    "## PyTorch Going Modular <a name=\"modular\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c204e3b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.387482Z",
     "start_time": "2023-03-21T15:53:23.570405Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c3d5cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.403504Z",
     "start_time": "2023-03-21T15:53:26.390501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e123d0",
   "metadata": {},
   "source": [
    "What exactly does it mean to go modular? Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality. For example, a series of cells in a Jupyter Notebook file could be transformed into the following files:\n",
    "\n",
    "- data_setup.py: A file to prepare and download data if needed\n",
    "- engine.py: A file containing various training functions\n",
    "- model.py: A file to create a PyTorch model\n",
    "- train.py: A file to leverage all the other files and train a large PyTorch model\n",
    "- utils.py: A file to store helpful utility functions in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c65d27",
   "metadata": {},
   "source": [
    "The naming convention and distribution of code among files is obviously customizable and depends on context. Notebooks are fantastic for iteratively exploring and running experiments quickly. However, for larger scale projects you may find Python scripts more reproducible and easier to run. There's arguments to be had for both sides of the coin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db5cb1b",
   "metadata": {},
   "source": [
    "Jupyter Notebook files are easy to start with, they're easy to share, and they're very visual-oriented. However, versioning can be difficult, it's harder to use only specific parts, and text and graphics can get in the way of the code. Python scripts can package code together, can easily use git for versioning, many open source projects use Python scripts, and larger projects can be run on cloud vendors (so can Notebook files but there's not as much support). However, experimenting with code isn't as visual and you usually have to run the whole script instead of a single code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd857e61",
   "metadata": {},
   "source": [
    "<img src=\"images/05_pytorch_script_example.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c890e",
   "metadata": {},
   "source": [
    "Many code repositories for PyTorch-based ML projects have instructions on how to run the PyTorch code in the form of Python scripts. The above is such an example, tailored after usage of the TinyVGG model that has been recreated in previous Notebooks. Here, `train.py` is the target Python script and the other sections are argument flags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84305e",
   "metadata": {},
   "source": [
    "Note: it's not necessary to create Python scripts via a notebook. It's possible to create them directly through an IDE such as Visual Studio Code. Creating the scripts through code cells in this Notebook is just to show off one way of creating Python script files and to keep the lesson in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f82a75",
   "metadata": {},
   "source": [
    "## Data Setup <a name=\"setup\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a9cd113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.419477Z",
     "start_time": "2023-03-21T15:53:26.406486Z"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = Path(\"data/PizzaSteakSushi\")\n",
    "TRAIN_DIR = Path(f\"{IMAGE_PATH}/train\")\n",
    "TEST_DIR = Path(f\"{IMAGE_PATH}/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f4e76f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.434797Z",
     "start_time": "2023-03-21T15:53:26.423477Z"
    }
   },
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c1d1ff",
   "metadata": {},
   "source": [
    "The creation process of datasets and DataLoaders can be combined into one function and saved in an external Python file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5b253f",
   "metadata": {},
   "source": [
    "This file will be called `data_setup.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5cc0e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.450721Z",
     "start_time": "2023-03-21T15:53:26.437795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/data_setup.py\n",
    "\"\"\"\n",
    "Contains functionality for creating PyTorch DataLoaders for custom image classification data.\n",
    "\"\"\"\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    test_dir: str,\n",
    "    transform: transforms.Compose,\n",
    "    batch_size: int,\n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates training and testing DataLoaders \n",
    "    Takes in training and testing directory paths and turns their contents into PyTorch datasets, and then into PyTorch DataLoaders\n",
    "    \n",
    "    Parameters:\n",
    "        train_dir: Path to the training directory\n",
    "        test_dir: Path to the testing directory\n",
    "        transform: A Torchvision transform to perform on the training and testing data\n",
    "        batch_size: Sample size for the batches in the DataLoaders\n",
    "        num_workers: Number of workers (CPU/GPU cores) per DataLoader\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "        Where class_names is a list of the target classes.\n",
    "    \"\"\"\n",
    "    # Create datasets with datasets.ImageFolder()\n",
    "    train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "    test_data = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = train_data.classes\n",
    "    \n",
    "    # Transform datasets into DataLoaders\n",
    "    train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, num_workers=NUM_WORKERS, shuffle=True)\n",
    "    test_dataloader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=NUM_WORKERS, shuffle=False)\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d23431d",
   "metadata": {},
   "source": [
    "The creation of DataLoaders can now be achieved by importing the created file and its functions into this Jupyter Notebook file and then calling the function and supplying the necessary arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30defdd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.465605Z",
     "start_time": "2023-03-21T15:53:26.453710Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing data_setup.py\n",
    "from modular_scripts import data_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b81b57a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.481599Z",
     "start_time": "2023-03-21T15:53:26.468606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating DataLoaders and class names\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(TRAIN_DIR, \n",
    "                                                                               TEST_DIR, \n",
    "                                                                               simple_transform, \n",
    "                                                                               32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e2e6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.496601Z",
     "start_time": "2023-03-21T15:53:26.484597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many batches each DataLoader has\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180341f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.511994Z",
     "start_time": "2023-03-21T15:53:26.499588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12104d72",
   "metadata": {},
   "source": [
    "## Building a Model <a name=\"buildmodel\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d477051",
   "metadata": {},
   "source": [
    "In the previous chapters, image classification models mimicking a TinyVGG architecture were created at multiple points. While recreating the code multiple times is good for practice, saving the code in an external Python file will prove to be useful for reusability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f54f5b",
   "metadata": {},
   "source": [
    "This file will be called `model_builder.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c55eef35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.527151Z",
     "start_time": "2023-03-21T15:53:26.516990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/model_builder.py\n",
    "\"\"\"\n",
    "Contains PyTorch model code to instantiate a TinyVGG model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Creates the TinyVGG architecture.\n",
    "    \n",
    "    Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "    See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "    \n",
    "    Parameters:\n",
    "        in_shape: An integer indicating the number of input layer neurons.\n",
    "        hidden: An integer indicating the number of hidden layer neurons.\n",
    "        out_shape: An integer indicating the number of output layer neurons.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_shape: int, hidden: int, out_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_shape, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden, out_channels=hidden, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden*13*13, out_features=out_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c8482",
   "metadata": {},
   "source": [
    "Instead of coding the TinyVGG model from scratch every time, it's now possible to create it by importing the relevant file, function, and calling it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ba49b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.543019Z",
     "start_time": "2023-03-21T15:53:26.530133Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing model_builder.py\n",
    "from modular_scripts import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc41fbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.558189Z",
     "start_time": "2023-03-21T15:53:26.546007Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating an instance of the TinyVGG model class\n",
    "torch.manual_seed(42)\n",
    "model_0 = model_builder.TinyVGG(3, 10, len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9725195a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.589178Z",
     "start_time": "2023-03-21T15:53:26.561177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "TinyVGG                                  [1, 3]                    --\n",
       "├─Sequential: 1-1                        [1, 10, 30, 30]           --\n",
       "│    └─Conv2d: 2-1                       [1, 10, 62, 62]           280\n",
       "│    └─ReLU: 2-2                         [1, 10, 62, 62]           --\n",
       "│    └─Conv2d: 2-3                       [1, 10, 60, 60]           910\n",
       "│    └─ReLU: 2-4                         [1, 10, 60, 60]           --\n",
       "│    └─MaxPool2d: 2-5                    [1, 10, 30, 30]           --\n",
       "├─Sequential: 1-2                        [1, 10, 13, 13]           --\n",
       "│    └─Conv2d: 2-6                       [1, 10, 28, 28]           910\n",
       "│    └─ReLU: 2-7                         [1, 10, 28, 28]           --\n",
       "│    └─Conv2d: 2-8                       [1, 10, 26, 26]           910\n",
       "│    └─ReLU: 2-9                         [1, 10, 26, 26]           --\n",
       "│    └─MaxPool2d: 2-10                   [1, 10, 13, 13]           --\n",
       "├─Sequential: 1-3                        [1, 3]                    --\n",
       "│    └─Flatten: 2-11                     [1, 1690]                 --\n",
       "│    └─Linear: 2-12                      [1, 3]                    5,073\n",
       "==========================================================================================\n",
       "Total params: 8,083\n",
       "Trainable params: 8,083\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 5.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.71\n",
       "Params size (MB): 0.03\n",
       "Estimated Total Size (MB): 0.79\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reviewing the model summary\n",
    "summary(model_0, input_size=[1, 3, 64, 64], device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce1bfb",
   "metadata": {},
   "source": [
    "It's also possible to save the training and testing loops in external files as well. This essentially has been done multiple times already as the training and testing loops were turned into functions at several points. The same will be done here, but the code is saved in an external file to increase reusability even further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97285565",
   "metadata": {},
   "source": [
    "This file will be called `engine.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cba782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.605151Z",
     "start_time": "2023-03-21T15:53:26.592160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/engine.py\n",
    "\"\"\"\n",
    "Contains functions for training and testing a PyTorch model.\n",
    "\"\"\"\n",
    "import torch\n",
    "from typing import Dict, List, Tuple\n",
    "import torchmetrics\n",
    "\n",
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               metric_fn: torchmetrics.classification) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Trains a PyTorch model for a single epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be trained on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        metric_fn: A PyTorch metric to track how well the model performs.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of training loss and training accuracy metrics.\n",
    "        In the form (train_loss, train_accuracy).\n",
    "    \"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_logits = model(X)\n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "        loss = loss_fn(y_logits, y)\n",
    "        train_loss += loss\n",
    "        train_acc += metric_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              metric_fn: torchmetrics.classification) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Tests a PyTorch model for a single epoch.\n",
    "    \n",
    "    Parameters:\n",
    "        model: A PyTorch model to be trained.\n",
    "        dataloader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        metric_fn: A PyTorch metric to track how well the model performs.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of testing loss and testing accuracy metrics.\n",
    "        In the form (test_loss, test_accuracy).\n",
    "    \"\"\"\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            test_logits = model(X)\n",
    "            test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "            test_loss += loss_fn(test_logits, y)\n",
    "            test_acc += metric_fn(test_pred, y)\n",
    "            \n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          metric_fn: torchmetrics.classification,\n",
    "          epochs: int) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Trains and tests a PyTorch model.\n",
    "    \n",
    "    Passes a target PyTorch models through train_step() and test_step() functions.\n",
    "    For a number of epochs, training and testing steps for model the model are performed.\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "    \n",
    "    Parameters:\n",
    "        model: A PyTorch model to be trained.\n",
    "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to minimize.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        metric_fn: A PyTorch metric to track how well the model performs.\n",
    "        epochs: An integer indicating how many epochs to train for.\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and testing accuracy metrics. \n",
    "        Each metric has a value in a list for each epoch.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_step(model, train_dataloader, loss_fn, optimizer, metric_fn)\n",
    "        test_loss, test_acc = test_step(model, test_dataloader, loss_fn, metric_fn)\n",
    "        \n",
    "        print(f\"Epoch: {epoch}\\n--------\")\n",
    "        print(f\"Train Loss: {train_loss}, Train Acc: {train_acc} | Test Loss: {test_loss}, Test Acc: {test_acc}\")\n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        \n",
    "    #return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bf138d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.621142Z",
     "start_time": "2023-03-21T15:53:26.610149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing engine.py\n",
    "from modular_scripts import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e28c850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:53:26.637133Z",
     "start_time": "2023-03-21T15:53:26.625141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the loss function, optimizer, and metric function to pass to the model\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "212a55d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:54:26.895215Z",
     "start_time": "2023-03-21T15:53:26.641131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "--------\n",
      "Train Loss: 1.1045265197753906, Train Acc: 0.265625 | Test Loss: 1.0925774574279785, Test Acc: 0.2604166567325592\n",
      "Epoch: 1\n",
      "--------\n",
      "Train Loss: 1.083570957183838, Train Acc: 0.38671875 | Test Loss: 1.0558981895446777, Test Acc: 0.5416666865348816\n",
      "Epoch: 2\n",
      "--------\n",
      "Train Loss: 1.0705418586730957, Train Acc: 0.40234375 | Test Loss: 1.0242347717285156, Test Acc: 0.5416666865348816\n",
      "Epoch: 3\n",
      "--------\n",
      "Train Loss: 1.0964175462722778, Train Acc: 0.28515625 | Test Loss: 1.000772476196289, Test Acc: 0.5625\n",
      "Epoch: 4\n",
      "--------\n",
      "Train Loss: 1.0600786209106445, Train Acc: 0.359375 | Test Loss: 1.0676933526992798, Test Acc: 0.374053031206131\n"
     ]
    }
   ],
   "source": [
    "engine.train(model_0, train_dataloader, test_dataloader, loss_fn, optimizer, metric_fn, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb4c5b",
   "metadata": {},
   "source": [
    "## Saving a Model <a name=\"savemodel\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be97be",
   "metadata": {},
   "source": [
    "It's often necessary to save a model whilst it's training or after training. Since code was written to save a model a few times now in previous notebooks, it makes sense to turn it into a function and save it to file. It's common practice to store helper functions in a another file for utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9095da66",
   "metadata": {},
   "source": [
    "This file will be called `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7224228",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:54:26.911206Z",
     "start_time": "2023-03-21T15:54:26.899212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/utils.py\n",
    "\"\"\"\n",
    "Contains various utility functions for PyTorch model training and saving.\n",
    "\"\"\"\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model(model: torch.nn.Module,\n",
    "               target_dir: str,\n",
    "               model_name: str) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Saves a PyTorch model to a target directory.\n",
    "    \n",
    "    Parameters:\n",
    "        model: A PyTorch model to save.\n",
    "        target_dir: The directory to save the model to.\n",
    "        model_name: The filename to give to the model, should use \".pth\" or \".pt\" as the file extension.\n",
    "    \"\"\"\n",
    "    target_dir_path = Path(target_dir)\n",
    "    target_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\")\n",
    "    model_save_path = Path(f\"{target_dir_path}/{model_name}\")\n",
    "    \n",
    "    print(f\"Saving model to: {model_save_path}\")\n",
    "    torch.save(obj=model.state_dict(), f=model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdbf75a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:54:26.927189Z",
     "start_time": "2023-03-21T15:54:26.915222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing utils.py\n",
    "from modular_scripts import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7ba2f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:54:26.943179Z",
     "start_time": "2023-03-21T15:54:26.930187Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the model with the new imported function\n",
    "#utils.save_model(model=model_0, target_dir=\"models\", model_name=\"05_pytorch_going_modular_model_test.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2bc357",
   "metadata": {},
   "source": [
    "## Everything Combined <a name=\"combined\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf32b0",
   "metadata": {},
   "source": [
    "While all the usual steps for working with PyTorch models have been handled, they're currently all split up into separate files. Going through the motions would still require calling multiple scripts and manually saving any output for reuse in subsequent scripts. To accomplish the goal of full modularity that will allow for a model to be used by a single command line prompt, it's necessary to create another file that imports and utilizes all of the previously made files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b9fd5f",
   "metadata": {},
   "source": [
    "This file will be called `train.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af252df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-21T15:54:26.959172Z",
     "start_time": "2023-03-21T15:54:26.946178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting modular_scripts/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile modular_scripts/train.py\n",
    "\"\"\"\n",
    "Trains a PyTorch image classification model.\n",
    "\"\"\"\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy\n",
    "import data_setup, engine, model_builder, utils\n",
    "\n",
    "def main():\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 32\n",
    "    HIDDEN_UNITS = 10\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    IMAGE_PATH = Path(\"../data/PizzaSteakSushi\")\n",
    "    TRAIN_DIR = Path(f\"{IMAGE_PATH}/train\")\n",
    "    TEST_DIR = Path(f\"{IMAGE_PATH}/test\")\n",
    "\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "        train_dir=TRAIN_DIR,\n",
    "        test_dir=TEST_DIR,\n",
    "        transform=data_transform,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    model = model_builder.TinyVGG(\n",
    "        in_shape=3,\n",
    "        hidden=HIDDEN_UNITS,\n",
    "        out_shape=len(class_names)\n",
    "    )\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)\n",
    "    metric_fn = Accuracy(task=\"multiclass\", num_classes=len(class_names))\n",
    "\n",
    "    engine.train(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        metric_fn=metric_fn,\n",
    "        epochs=EPOCHS\n",
    "    )\n",
    "\n",
    "    utils.save_model(\n",
    "        model=model,\n",
    "        target_dir=\"../models\",\n",
    "        model_name=\"05_pytorch_going_modular_tinyvgg.pth\"\n",
    "    )\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087dda8c",
   "metadata": {},
   "source": [
    "It's now possible to call `train.py` from the command line to run this script, which will go through all the other scripts and essentially perform the entire workflow necessary to train a TinyVGG architecture model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979db00",
   "metadata": {},
   "source": [
    "The script can be run in the command line with: `python train.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
