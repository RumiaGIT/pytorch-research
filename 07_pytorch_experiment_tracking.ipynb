{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a121c09",
   "metadata": {},
   "source": [
    "# 07. PyTorch Experiment Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8555785",
   "metadata": {},
   "source": [
    "https://www.learnpytorch.io/07_pytorch_experiment_tracking/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a358a5",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9592be",
   "metadata": {},
   "source": [
    "- [All Links in Document](#links)\n",
    "- [Prepare Data and Model](#prep)\n",
    "- [Training a Model](#trainmodel)\n",
    "- [Using TensorBoard](#usetb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89018204",
   "metadata": {},
   "source": [
    "## All Links in Document <a name=\"links\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b089595a",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/tensorboard/\n",
    "- https://code.visualstudio.com/docs/datascience/pytorch-support#_tensorboard-integration\n",
    "- c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f770813",
   "metadata": {},
   "source": [
    "## PyTorch Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79094b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.173660Z",
     "start_time": "2023-04-04T10:12:28.557245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics import Accuracy\n",
    "from torchinfo import summary\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09541297",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.189653Z",
     "start_time": "2023-04-04T10:12:35.177657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n",
      "0.14.1+cu117\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05c01",
   "metadata": {},
   "source": [
    "So far, plenty of various models have been created, experimented with, and improved over multiple iterations. So far, keeping track of results was done by manually creating dictionaries. This is a rather simple and effective, but rookie approach. Such simple methods may quickly become unsustainable as models grow, or in scenarios where many models are run simultaneously.\n",
    "\n",
    "The concept of experiment tracking is extremely important and integral to machine learning and deep learning as they are naturally experimental. As experiments and changes are tinkered with, it's necessary to keep track of everything that is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba932d",
   "metadata": {},
   "source": [
    "<img src=\"images/07_experiment_tracking_examples.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d36e43",
   "metadata": {},
   "source": [
    "The above image illustrates various example of experiment tracking. As stated, it's possible to do it manually through various dictionaries and files, but there are more professional methods available too. This Notebook will focus on TensorBoard due to its widespread use and integration with PyTorch. It's free to use and will only require the installation of the `tensorboard` package. More information about TensorBoard can be found on the Tensorflow website: https://www.tensorflow.org/tensorboard/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c22ba",
   "metadata": {},
   "source": [
    "The principles to be followed remain the same overall, but some new elements will be included:\n",
    "\n",
    "- Acquire data\n",
    "- Create datasets and dataloaders\n",
    "- Load and customize a pretrained modele\n",
    "- Train model and track results\n",
    "- View results in TensorBoard\n",
    "- Create a helper function to track experiments\n",
    "- Set up a series of modelling experiments\n",
    "- View modelling experiments' results in TensorBoard\n",
    "- Load the best performing model and make predictions with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaed3dc",
   "metadata": {},
   "source": [
    "*NOTE: Code is handwritten again for even more practice!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc04ec",
   "metadata": {},
   "source": [
    "## Prepare Data and Model <a name=\"prep\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0580c362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.219632Z",
     "start_time": "2023-04-04T10:12:35.193648Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating data paths\n",
    "IMAGE_PATH = Path(\"data/PizzaSteakSushi\")\n",
    "TRAIN_DIR = Path(f\"{IMAGE_PATH}/train\")\n",
    "TEST_DIR = Path(f\"{IMAGE_PATH}/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21d6ce",
   "metadata": {},
   "source": [
    "As a pretrained model is to be used, and the creation of datasets requires the usage of the same transform as the pretrained model's transform, it's first necessary to load the pretrained model and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2c0a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.517116Z",
     "start_time": "2023-04-04T10:12:35.223632Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading pretrained model and weights\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model = torchvision.models.efficientnet_b0(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdfe1a77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.548099Z",
     "start_time": "2023-04-04T10:12:35.523111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the pretrained model's transforms\n",
    "auto_transforms = weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab65920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.579079Z",
     "start_time": "2023-04-04T10:12:35.553094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_data = datasets.ImageFolder(root=TRAIN_DIR, transform=auto_transforms)\n",
    "test_data = datasets.ImageFolder(root=TEST_DIR, transform=auto_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f7e2ee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.594072Z",
     "start_time": "2023-04-04T10:12:35.584077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders and class names\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=32, num_workers=os.cpu_count(), shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=32, num_workers=os.cpu_count(), shuffle=False)\n",
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30557bb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.626052Z",
     "start_time": "2023-04-04T10:12:35.599068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freezing the model's base layers\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c84f48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.641044Z",
     "start_time": "2023-04-04T10:12:35.631050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking model's default classifier\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8305843",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.672028Z",
     "start_time": "2023-04-04T10:12:35.646041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Updating model's default classifier to suit the custom problem\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "487a9118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:35.703009Z",
     "start_time": "2023-04-04T10:12:35.676024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking model's updated classifier\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36d27b18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:38.258844Z",
     "start_time": "2023-04-04T10:12:35.707008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape         Output Shape        Param #             Trainable\n",
       "===================================================================================================================================\n",
       "EfficientNet                                            [32, 3, 224, 224]   [32, 3]             --                  Partial\n",
       "├─Sequential: 1-1                                       [32, 3, 224, 224]   [32, 1280, 7, 7]    --                  False\n",
       "│    └─Conv2dNormActivation: 2-1                        [32, 3, 224, 224]   [32, 32, 112, 112]  --                  False\n",
       "│    │    └─Conv2d: 3-1                                 [32, 3, 224, 224]   [32, 32, 112, 112]  (864)               False\n",
       "│    │    └─BatchNorm2d: 3-2                            [32, 32, 112, 112]  [32, 32, 112, 112]  (64)                False\n",
       "│    │    └─SiLU: 3-3                                   [32, 32, 112, 112]  [32, 32, 112, 112]  --                  --\n",
       "│    └─Sequential: 2-2                                  [32, 32, 112, 112]  [32, 16, 112, 112]  --                  False\n",
       "│    │    └─MBConv: 3-4                                 [32, 32, 112, 112]  [32, 16, 112, 112]  (1,448)             False\n",
       "│    └─Sequential: 2-3                                  [32, 16, 112, 112]  [32, 24, 56, 56]    --                  False\n",
       "│    │    └─MBConv: 3-5                                 [32, 16, 112, 112]  [32, 24, 56, 56]    (6,004)             False\n",
       "│    │    └─MBConv: 3-6                                 [32, 24, 56, 56]    [32, 24, 56, 56]    (10,710)            False\n",
       "│    └─Sequential: 2-4                                  [32, 24, 56, 56]    [32, 40, 28, 28]    --                  False\n",
       "│    │    └─MBConv: 3-7                                 [32, 24, 56, 56]    [32, 40, 28, 28]    (15,350)            False\n",
       "│    │    └─MBConv: 3-8                                 [32, 40, 28, 28]    [32, 40, 28, 28]    (31,290)            False\n",
       "│    └─Sequential: 2-5                                  [32, 40, 28, 28]    [32, 80, 14, 14]    --                  False\n",
       "│    │    └─MBConv: 3-9                                 [32, 40, 28, 28]    [32, 80, 14, 14]    (37,130)            False\n",
       "│    │    └─MBConv: 3-10                                [32, 80, 14, 14]    [32, 80, 14, 14]    (102,900)           False\n",
       "│    │    └─MBConv: 3-11                                [32, 80, 14, 14]    [32, 80, 14, 14]    (102,900)           False\n",
       "│    └─Sequential: 2-6                                  [32, 80, 14, 14]    [32, 112, 14, 14]   --                  False\n",
       "│    │    └─MBConv: 3-12                                [32, 80, 14, 14]    [32, 112, 14, 14]   (126,004)           False\n",
       "│    │    └─MBConv: 3-13                                [32, 112, 14, 14]   [32, 112, 14, 14]   (208,572)           False\n",
       "│    │    └─MBConv: 3-14                                [32, 112, 14, 14]   [32, 112, 14, 14]   (208,572)           False\n",
       "│    └─Sequential: 2-7                                  [32, 112, 14, 14]   [32, 192, 7, 7]     --                  False\n",
       "│    │    └─MBConv: 3-15                                [32, 112, 14, 14]   [32, 192, 7, 7]     (262,492)           False\n",
       "│    │    └─MBConv: 3-16                                [32, 192, 7, 7]     [32, 192, 7, 7]     (587,952)           False\n",
       "│    │    └─MBConv: 3-17                                [32, 192, 7, 7]     [32, 192, 7, 7]     (587,952)           False\n",
       "│    │    └─MBConv: 3-18                                [32, 192, 7, 7]     [32, 192, 7, 7]     (587,952)           False\n",
       "│    └─Sequential: 2-8                                  [32, 192, 7, 7]     [32, 320, 7, 7]     --                  False\n",
       "│    │    └─MBConv: 3-19                                [32, 192, 7, 7]     [32, 320, 7, 7]     (717,232)           False\n",
       "│    └─Conv2dNormActivation: 2-9                        [32, 320, 7, 7]     [32, 1280, 7, 7]    --                  False\n",
       "│    │    └─Conv2d: 3-20                                [32, 320, 7, 7]     [32, 1280, 7, 7]    (409,600)           False\n",
       "│    │    └─BatchNorm2d: 3-21                           [32, 1280, 7, 7]    [32, 1280, 7, 7]    (2,560)             False\n",
       "│    │    └─SiLU: 3-22                                  [32, 1280, 7, 7]    [32, 1280, 7, 7]    --                  --\n",
       "├─AdaptiveAvgPool2d: 1-2                                [32, 1280, 7, 7]    [32, 1280, 1, 1]    --                  --\n",
       "├─Sequential: 1-3                                       [32, 1280]          [32, 3]             --                  True\n",
       "│    └─Dropout: 2-10                                    [32, 1280]          [32, 1280]          --                  --\n",
       "│    └─Linear: 2-11                                     [32, 1280]          [32, 3]             3,843               True\n",
       "===================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (G): 12.31\n",
       "===================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "==================================================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking summary of the model\n",
    "summary(model=model,\n",
    "        input_size=[32, 3, 224, 224],\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=19, \n",
    "        device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058eba9",
   "metadata": {},
   "source": [
    "The summary correctly shows how most of the params are non-trainable (as they were frozen earlier), and the output layer is correctly transformed to better suit the custom problem of the PizzaSteakSushi dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95577564",
   "metadata": {},
   "source": [
    "## Training a Model <a name=\"trainmodel\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35b4a276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:38.288827Z",
     "start_time": "2023-04-04T10:12:38.263841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating loss function, optimizer, and metric\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2116b8b",
   "metadata": {},
   "source": [
    "Previously, this is where multiple lists and dictionaries would be created to keep track of results during the training and testing loops. However, this is where `SummaryWriter` from `torch.utils.tensorboard` can have a chance to shine. By default, the `SummaryWriter` saves various information about a model to a file set by its `log_dir` parameter. The default location for these logs is `runs/CURRENT_DATETIME_HOSTNAME`, where the `HOSTNAME` is the name of the computer. It's of course customizable where experiments are tracked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4db6b6",
   "metadata": {},
   "source": [
    "The outputs of the `SummaryWriter()` are saved in TensorBoard format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a63daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:12:38.318810Z",
     "start_time": "2023-04-04T10:12:38.297822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a TensorBoard writer with all default settings\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661898b6",
   "metadata": {},
   "source": [
    "To make use of this writer, it's necessary to make several changes to the training and testing loops. To save loss and accuracy values, it's possible to use the `add_scalars(main_tag, tag_scalar_dict)` method of the writer where:\n",
    "\n",
    "- `main_tag` (string) is the name for the scalars being tracked, e.g., \"Accuracy\"\n",
    "- `tag_scalar_dict` (dict) is a dictionary of the values being tracked, e.g., `{\"train_loss\": 0.1234}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54debd4",
   "metadata": {},
   "source": [
    "This method is called `add_scalars()` as the loss and accuracy values are generally scalars (single values). Afterwards, it's necessary to call `writer.close()` to tell the writer to stop looking for values to track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2ba6a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T10:16:35.437027Z",
     "start_time": "2023-04-04T10:12:38.323807Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train Loss: 1.10574, Train Acc: 0.37 | Test Loss: 0.92652, Test Acc: 0.61\n",
      "Epoch: 1\n",
      "Train Loss: 0.91985, Train Acc: 0.66 | Test Loss: 0.84583, Test Acc: 0.64\n",
      "Epoch: 2\n",
      "Train Loss: 0.79064, Train Acc: 0.75 | Test Loss: 0.67777, Test Acc: 0.91\n",
      "Epoch: 3\n",
      "Train Loss: 0.68648, Train Acc: 0.79 | Test Loss: 0.64276, Test Acc: 0.86\n",
      "Epoch: 4\n",
      "Train Loss: 0.65532, Train Acc: 0.80 | Test Loss: 0.62078, Test Acc: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Updated training and testing loop to accommodate SummaryWriter\n",
    "torch.manual_seed(42)\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        y_logits = model(X)\n",
    "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)\n",
    "        loss = loss_fn(y_logits, y)\n",
    "        train_loss += loss\n",
    "        train_acc += metric_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            test_logits = model(X)\n",
    "            test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "            test_loss += loss_fn(test_logits, y)\n",
    "            test_acc += metric_fn(test_pred, y)\n",
    "            \n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(f\"Train Loss: {train_loss:.5f}, Train Acc: {train_acc:.2f} | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}\")\n",
    "\n",
    "    writer.add_scalars(main_tag=\"Loss\", global_step=epoch, tag_scalar_dict={\"train_loss\": train_loss, \n",
    "                                                                            \"test_loss\": test_loss})\n",
    "    \n",
    "    writer.add_scalars(main_tag=\"Accuracy\", global_step=epoch, tag_scalar_dict={\"train_acc\": train_acc, \n",
    "                                                                                \"test_acc\": test_acc})\n",
    "    \n",
    "    writer.add_graph(model=model, input_to_model=torch.randn(32, 3, 224, 224))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25797d4c",
   "metadata": {},
   "source": [
    "## Using TensorBoard <a name=\"usetb\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202cc5ff",
   "metadata": {},
   "source": [
    "The `SummaryWriter()` class stores the model's results in a directory called `runs/` in TensorBoard format by default. TensorBoard is a visualization program created by the TensorFlow team to view and inspect information about models and data. It's possible to view this TensorBoard in multiple environments:\n",
    "\n",
    "- Visual Studio Code\n",
    "- Jupyter and Colab Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd55b9a",
   "metadata": {},
   "source": [
    "For the Visual Studio Code method, press `SHIFT + CMD + P` to open the command palette and search for the command: `Python: Launch TensorBoard`. More information about using Visual Studio Code for this purpose can be found here: https://code.visualstudio.com/docs/datascience/pytorch-support#_tensorboard-integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855db861",
   "metadata": {},
   "source": [
    "For the Jupyter and Colab Notebooks method, it's necessary that the `tensorboard` extension is installed. It's then possible to start an interactive TensorBoard session to view TensorBoard files in the runs/ directory. This is done with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b32c0268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-04T12:14:13.108348Z",
     "start_time": "2023-04-04T12:14:09.502457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-64bf9f7fe221be63\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-64bf9f7fe221be63\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb84b9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
